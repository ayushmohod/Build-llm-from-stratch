{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd2eb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232311\n",
      "\n",
      "\n",
      "\n",
      "  DOROTHY AND THE WIZARD IN OZ\n",
      "\n",
      "  BY\n",
      "\n",
      "  L. FRANK BAUM\n",
      "\n",
      "  AUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n",
      "\n",
      "  ILLUSTRATED BY JOHN R. NEILL\n",
      "\n",
      "  BOOKS OF WONDER WILLIAM MORROW & CO., INC. N\n"
     ]
    }
   ],
   "source": [
    "# take small data set to make a biogram out of it model\n",
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:# open the txt file in readmode('r') with encoding of utf-8\n",
    "    text=f.read()\n",
    "print(len(text))#length of text\n",
    "print(text[:200])#first 200 character of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b382d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "#make a vocab list\n",
    "chars=sorted(set(text)) #use this to find all the types of character used in this text file\n",
    "print(chars)\n",
    "vocablary_size=len(chars)\n",
    "print(vocablary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe02b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use tokenizer it consist of encoder, what encode does is that it convert each element of chars list to an interger\n",
    "#use generator for loop to map interger to char and char to integer\n",
    "string_to_int={ch:i for i,ch in enumerate(chars)}\n",
    "#above code create a dictionary of each character in chars with value as its index means each character is encoded as \n",
    "#its index number in (ch:i) and we use enumerate over chars list to get both character and index \n",
    "int_to_string={i:ch for i,ch in enumerate(chars)} # similary here decode back the integer to back to their characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cece4a",
   "metadata": {},
   "source": [
    "A lambda function is like a quick, one-time-use mini-function you can write in just one line. It's useful when you need a small function but don't want to formally define it using `def`. Think of it as a shortcut to make a simple function on the spot. For example, if you want to make a small function to add two numbers, instead of writing it out like this:\n",
    "\n",
    "```python\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "```\n",
    "\n",
    "You can use a lambda function to do it in one short line:\n",
    "\n",
    "```python\n",
    "add = lambda x, y: x + y\n",
    "```\n",
    "\n",
    "You can use it right away to add numbers, like `add(3, 4)`, and it will give you `7`. Lambda functions are handy for simple tasks, especially when you only need to use the function once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8b5a014",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode=lambda s: [string_to_int[c] for c in s]\n",
    "# This lambda function encodes a string s into a list of integers. For each character c in the string s, \n",
    "# it looks up the corresponding integer in the string_to_int dictionary and constructs a list of these integers.\n",
    "# This effectively converts the input string into a sequence of indices based on chars.\n",
    "decode=lambda l: ''.join([int_to_string[i] for i in l])\n",
    "# It takes a list of integers l and converts it back into a string. For each integer i in the list l, \n",
    "# it looks up the corresponding character in the int_to_string dictionary \n",
    "# and uses join to concatenate these characters into a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d8e8717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61, 58, 65, 65, 68]\n"
     ]
    }
   ],
   "source": [
    "print(encode('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bea24b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "encoded=encode('hello')\n",
    "decoded=decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86a26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we use character level tokennizer so we have a very small vocab and large amount of words to convert like 40k, i.e. why \n",
    "#we didn't use a word level tokenizer as it will be very large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd6a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to perfom efficient with data we use pytorch, help in working with maths of tensors\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d2067f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we make tensors so pytorch can easily work with it\n",
    "data=torch.tensor(encode(text),dtype=torch.long) #using this we encode text of book and with a datatype is that the encoded\n",
    "#integers are of long types, create a tensor and put our encoded words in that so torch can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aef1cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  0,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44,\n",
      "        32, 29,  1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,\n",
      "         1, 26, 49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25,\n",
      "        45, 37,  0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32,\n",
      "        29,  1, 47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32,\n",
      "        29,  1, 36, 25, 38, 28,  1, 39, 30,  1])\n"
     ]
    }
   ],
   "source": [
    "print(data[:100])#print first 100 integers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d5196",
   "metadata": {},
   "source": [
    "validation and train split(20-80), we split as if we train on entire thing it will memorize the entire thing and will only \n",
    "know this document but we to generate text which is like training text, something like training text of\n",
    "same style but not exactly that\n",
    "bigram model- bi means 2\n",
    "hello\n",
    "start of content -h\n",
    "h->e\n",
    "e->l\n",
    "l->l\n",
    "l->o\n",
    "so given the previous character it will try to predict the next character using probabilty\n",
    "how to do it in the neural network and train it\n",
    "let a small snippet out of our text box_size=5, make pridiction and target out of that\n",
    "....[5,67,21,58,40] 35.....\n",
    "here we have tensor[5,67,21,58,40] is the pridiction to context given before to it here index[0]=5\n",
    "...5[67,21,58,40,35].......\n",
    "here we have target which should be offset by 1, as 5 here is outside and 35 inside and here index[0]=67\n",
    "so 67 is following 5 in background language model\n",
    "and we simply check how far is pridiction away from target and optimize it for reducing error\n",
    "Sure, let's simplify this concept.\n",
    "\n",
    "A bigram model, like the one you're describing, is essentially a way to predict the next item in a sequence (like a character in a text) based on the previous item. The \"bi-\" in bigram means two, indicating that the model looks at pairs of items. In the context of a neural network, this model can be trained to predict the next character in a text sequence by learning from examples.\n",
    "\n",
    "Here's how you could train such a model with a neural network, step by step, in simplified terms:\n",
    "\n",
    "1. **Preparing the Data**: You start with a bunch of text (your dataset). You want your neural network to learn from this text how to predict the next character given the previous one. To do this, you first need to convert your text into a format that the neural network can understand. This usually means converting each character into a numerical representation, often using something called an \"index\" (where each unique character gets a unique number).\n",
    "\n",
    "2. **Creating Predictions and Targets**: You create pairs of sequences from your numerical text data. Each pair consists of:\n",
    "   - A **prediction sequence**, which is what you give the neural network to look at. For example, if your sequence is `[5,67,21,58,40]`, it means you're showing the characters represented by these numbers to the network.\n",
    "   - A **target sequence**, which is what you want the network to predict. It's the prediction sequence shifted by one position, like `[67,21,58,40,35]`. The idea is to make the network predict the next character in the sequence.\n",
    "\n",
    "3. **Training the Model**: With your data prepared, you now train your neural network. You feed it lots of these prediction-target pairs. The network makes a guess about the target based on the prediction sequence. At first, its guesses are random, but you tell it how close its guess was to the target (this is where you measure \"how far is prediction away from target\"). The neural network uses this feedback to adjust its internal settings slightly to improve its guesses next time.\n",
    "\n",
    "4. **Optimization**: This process of making a guess, getting feedback, and adjusting is repeated many times (thousands or even millions). Each time, the network gets a little bit better at predicting the next character. The goal is to minimize the error, which is the difference between what the network predicts and the actual next character in the sequence.\n",
    "\n",
    "In essence, you're teaching the neural network to understand the patterns in the text: which characters tend to follow others. Over time, as it sees more examples and gets more feedback, it gets better at making predictions. This whole process is a simplified view of training a bigram model with a neural network to predict the next character in a sequence based on the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c21150b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "n=int(0.8*len(data))\n",
    "train_data=data[:n]\n",
    "val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90b7a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([0]) target is tensor(0)\n",
      "when input is tensor([0, 0]) target is tensor(0)\n",
      "when input is tensor([0, 0, 0]) target is tensor(1)\n",
      "when input is tensor([0, 0, 0, 1]) target is tensor(1)\n",
      "when input is tensor([0, 0, 0, 1, 1]) target is tensor(28)\n",
      "when input is tensor([ 0,  0,  0,  1,  1, 28]) target is tensor(39)\n",
      "when input is tensor([ 0,  0,  0,  1,  1, 28, 39]) target is tensor(42)\n",
      "when input is tensor([ 0,  0,  0,  1,  1, 28, 39, 42]) target is tensor(39)\n"
     ]
    }
   ],
   "source": [
    "# we take random snippet from start upto block size of 5 i.e ....[5,67,21,58,40] 35.....[:5]\n",
    "# and ...5[67,21,58,40,35]....... [1:block_size+1] similar will be our code and this is how we train to pridict next letter\n",
    "#below we train our model on how to predict data  The idea here is to use a small window (or block) of the data to \n",
    "#teach the model how to predict the next character \n",
    "#(or item) based on the previous ones within that window.\n",
    "block_size=8\n",
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t]\n",
    "    print('when input is', context,'target is', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "but above one is sequential but not scable as gpu can do these task parallely and fast, \n",
    "so what we can is that we take each block stack them parrellely adn push them to gpu to scale it\n",
    "we have block [.......]\n",
    "stack the [.....]\n",
    "          [.....]\n",
    "          [.....]\n",
    "here block size is len of each block and batch size is how many we can put in parallel to give to gpu, good way to scale language \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f50215f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#check if gpu is availble for use or not\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49a67957",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter for gpu training\n",
    "block_size=8\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98047c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
